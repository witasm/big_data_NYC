{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da7c2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ba3b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, month, substring, max, avg, sum, count, min\n",
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b456eb7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/20 16:26:36 WARN util.Utils: Your hostname, node1 resolves to a loopback address: 127.0.0.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/12/20 16:26:36 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/12/20 16:26:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Jupyter Demo\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be4665",
   "metadata": {},
   "source": [
    "## Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f0161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sales(years):\n",
    "    year_one = years[0]\n",
    "    df_big = spark.read.option(\"header\",\n",
    "                               \"true\").option(\"inferschema\",\n",
    "                                              \"true\").csv(f'hdfs://localhost:8020//user/bd_project/batch_layer/neighborhood_sales/{str(year_one)}.csv')\n",
    "    years = years[1:]\n",
    "    for year in years:\n",
    "        df = spark.read.option(\"header\",\n",
    "                               \"true\").option(\"inferschema\",\n",
    "                                              \"true\").csv(f'hdfs://localhost:8020//user/bd_project/batch_layer/neighborhood_sales/{str(year)}.csv')\n",
    "        df_big = df_big.union(df)\n",
    "    return df_big"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aba99c",
   "metadata": {},
   "source": [
    "### Chiosen years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c54d2827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "y = [2016, 2018, 2021]\n",
    "df_sales = create_sales(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acd27bf",
   "metadata": {},
   "source": [
    "## 311 Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "110c96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_date_column(df):\n",
    "    df2 = df.withColumn('year', \n",
    "                             col('created_date').substr(1, 4) ).withColumn('month', \n",
    "                                                                           col('created_date').substr(6, 2) ) \n",
    "    df_new = df2.withColumn('day', \n",
    "                                 col('created_date').substr(9,2) ).withColumn('hour', \n",
    "                                                                               col('created_date').substr(12, 2) ) \n",
    "    return df_new\n",
    "\n",
    "def create_sevices(dates):\n",
    "    year_one = dates[0]\n",
    "    df_big = spark.read.option(\"header\",\"true\").option(\"inferschema\",\"true\").parquet(f'hdfs://localhost:8020/user/bd_project/batch_layer/311_service/{str(year_one)}.parquet')\n",
    "    df_big = df_big.drop('location')\n",
    "    cols = df_big.columns\n",
    "    dates = dates[1:]\n",
    "    for date in dates:\n",
    "        df = spark.read.option(\"header\",\"true\").option(\"inferschema\",\"true\").parquet(f'hdfs://localhost:8020/user/bd_project/batch_layer/311_service/{str(date)}.parquet')\n",
    "        df = df.drop('location')\n",
    "        df = df.select(cols)\n",
    "        df_big = df_big.union(df)\n",
    "    return split_date_column(df_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538dbc8",
   "metadata": {},
   "source": [
    "### Chosen dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5daaee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "months = ['01', '06']\n",
    "days = ['01']\n",
    "for rok in y:\n",
    "    for month in months:\n",
    "        for day in days:\n",
    "            dates.append(str(rok) + '/' + month + '/' + str(rok) +'-' + month + '-' + day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93bbc000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[unique_key: string, created_date: string, closed_date: string, agency: string, agency_name: string, complaint_type: string, descriptor: string, location_type: string, incident_zip: string, incident_address: string, street_name: string, cross_street_1: string, cross_street_2: string, address_type: string, city: string, facility_type: string, status: string, due_date: string, resolution_description: string, resolution_action_updated_date: string, community_board: string, bbl: string, borough: string, x_coordinate_state_plane: string, y_coordinate_state_plane: string, open_data_channel_type: string, park_facility_name: string, park_borough: string, latitude: string, longitude: string, intersection_street_1: string, intersection_street_2: string, taxi_company_borough: string, taxi_pick_up_location: string, bridge_highway_name: string, bridge_highway_direction: string, road_ramp: string, bridge_highway_segment: string, vehicle_type: string, landmark: string, year: string, month: string, day: string, hour: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_services = create_sevices(dates)\n",
    "df_services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d078f03",
   "metadata": {},
   "source": [
    "## Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97130e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sales_measures(df):\n",
    "    new = df.groupBy('borough').agg(sum('number_of_sales').alias('SalesNumber'),\n",
    "                                             min('lowest_sale_price').alias('MinPrice'),\n",
    "                                             avg('average_sale_price').alias('AvgPrice'),\n",
    "                                             max('highest_sale_price').alias('MaxPrice'))\n",
    "    view_name = \"sales_measures\"\n",
    "    new.createOrReplaceTempView(view_name)\n",
    "    return new, view_name\n",
    "\n",
    "def sales_measures_by_neighborhood(df):\n",
    "    new = df.groupBy('year', 'borough', 'neighborhood').agg(sum('number_of_sales').alias('SalesNumber'),\n",
    "                                             min('lowest_sale_price').alias('MinPrice'),\n",
    "                                             avg('average_sale_price').alias('AvgPrice'),\n",
    "                                             max('highest_sale_price').alias('MaxPrice'))\n",
    "    view_name = \"sales_measures_by_n\"\n",
    "    new.createOrReplaceTempView(view_name)\n",
    "    return new.orderBy('borough', 'year'), view_name\n",
    "\n",
    "\n",
    "\n",
    "def get_popular_incidents(df):\n",
    "    grouped_df = df.groupBy('borough', 'complaint_type')\n",
    "\n",
    "    # Calculate the count of each value in the grouped DataFrame\n",
    "    count_df = grouped_df.agg(count('complaint_type').alias('ComplaintCount'))\n",
    "\n",
    "    # Find the mode by ordering in descending order based on the count and selecting the first row\n",
    "    mode_df = count_df.groupBy('borough').agg(max('ComplaintCount').alias('ComplaintCount'))\n",
    "    joined = mode_df.join(count_df, on=['borough', 'ComplaintCount'], how='inner')\n",
    "    view_name = \"popular_incidents\"\n",
    "    joined.createOrReplaceTempView(view_name)\n",
    "    return joined.orderBy('ComplaintCount',  ascending=False), view_name\n",
    "\n",
    "def get_incidents_by_borough(df):\n",
    "    grouped_df = df.groupBy('borough')\n",
    "\n",
    "    count_df = grouped_df.agg(count('complaint_type').alias('ComplaintCount'))\n",
    "    view_name = \"incidents_by_borough\"\n",
    "    count_df.createOrReplaceTempView(view_name)\n",
    "    return count_df, view_name\n",
    "\n",
    "def get_incidents_by_borough_time(df):\n",
    "    grouped_df = df.groupBy('borough', 'year', 'month', 'day')\n",
    "\n",
    "    count_df = grouped_df.agg(count('complaint_type').alias('ComplaintCount'))\n",
    "    view_name = \"incidents_by_borough_time\"\n",
    "    count_df.createOrReplaceTempView(view_name)\n",
    "    return count_df, view_name\n",
    "\n",
    "\n",
    "def get_incidents_by_type(df):\n",
    "    grouped_df = df.groupBy('borough', 'location_type')\n",
    "\n",
    "    # Calculate the count of each value in the grouped DataFrame\n",
    "    count_df = grouped_df.agg(count('complaint_type').alias('ComplaintCount'))\n",
    "    view_name = \"incidents_by_type\"\n",
    "    count_df.createOrReplaceTempView(view_name)\n",
    "    return count_df.orderBy('ComplaintCount', ascending=False), view_name\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_incidents_by_channel_type(df):\n",
    "    grouped_df = df.groupBy('year', 'open_data_channel_type')\n",
    "\n",
    "    count_df = grouped_df.agg(count('complaint_type').alias('ComplaintCount'))\n",
    "    view_name = \"incidents_by_channel_type\"\n",
    "    count_df.createOrReplaceTempView(view_name)\n",
    "    return count_df.orderBy('ComplaintCount', ascending=False), view_name\n",
    "\n",
    "\n",
    "def get_incidents_by_street(df, hours):\n",
    "    df = df.withColumn(\"Hour\", col(\"hour\").cast(\"int\"))\n",
    "    df = df.filter(df['street_name'] != 'N/A')\n",
    "    df = df.filter( (df['hour'] >= hours[0]) & (df[\"hour\"] <= hours[1]) )\n",
    "    grouped_df = df.groupBy('borough', 'street_name')\n",
    "\n",
    "    # Calculate the count of each value in the grouped DataFrame\n",
    "    count_df = grouped_df.agg(count('complaint_type').alias('ComplaintCount'))\n",
    "    view_name = \"incidents_by_street\"\n",
    "    count_df.createOrReplaceTempView(\"incidents_by_street\")\n",
    "    return count_df.orderBy('ComplaintCount', ascending=False), view_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b2090",
   "metadata": {},
   "source": [
    "## 10 neighborhoods with most houses sold in 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f4313b20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 200:================================================>    (184 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+-----------+--------+---------+---------+\n",
      "|      neighborhood|      borough|SalesNumber|MinPrice| AvgPrice| MaxPrice|\n",
      "+------------------+-------------+-----------+--------+---------+---------+\n",
      "|    FLUSHING-NORTH|       QUEENS|        767|  200000|1249121.0|6600000.0|\n",
      "|       GREAT KILLS|STATEN ISLAND|        636|  200000| 700240.0|1400000.0|\n",
      "|           BAYSIDE|       QUEENS|        528|  200000|1152375.0|2460000.0|\n",
      "|        ST. ALBANS|       QUEENS|        412|  211975| 624832.0|1374243.0|\n",
      "|      BOROUGH PARK|     BROOKLYN|        401|  200000|1448466.0|3700000.0|\n",
      "|BEDFORD STUYVESANT|     BROOKLYN|        398|  230000|1558251.0|4550000.0|\n",
      "|    QUEENS VILLAGE|       QUEENS|        387|  200000| 746159.0|1400000.0|\n",
      "|     RICHMOND HILL|       QUEENS|        381|  247500| 818856.0|1820000.0|\n",
      "|    MIDDLE VILLAGE|       QUEENS|        364|  267142| 964018.0|2700000.0|\n",
      "|     EAST NEW YORK|     BROOKLYN|        356|  260000| 701756.0|1347775.0|\n",
      "+------------------+-------------+-----------+--------+---------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "year = 2021\n",
    "_, name = sales_measures_by_neighborhood(df_sales)\n",
    "view_df = spark.sql(f'''\n",
    "    SELECT neighborhood, borough, SalesNumber, MinPrice, ROUND(AvgPrice, 0) as AvgPrice, MaxPrice\n",
    "    FROM {name}\n",
    "    WHERE year = {year}\n",
    "    ORDER BY SalesNumber DESC\n",
    "    LIMIT 10\n",
    "    ''')\n",
    "view_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0783e",
   "metadata": {},
   "source": [
    "## 10 neighborhoods with lowest average price of house in 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef86495a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 203:=================================================>   (185 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------+-----------+\n",
      "|        neighborhood|      borough|AvgPrice|SalesNumber|\n",
      "+--------------------+-------------+--------+-----------+\n",
      "|          PORT IVORY|STATEN ISLAND|457652.0|         16|\n",
      "|       BROAD CHANNEL|       QUEENS|460297.0|         35|\n",
      "|         HUNTS POINT|        BRONX|468387.0|          8|\n",
      "|DONGAN HILLS-OLD ...|STATEN ISLAND|479000.0|          3|\n",
      "|   CONCORD-FOX HILLS|STATEN ISLAND|496194.0|         36|\n",
      "|     MARINERS HARBOR|STATEN ISLAND|501928.0|        153|\n",
      "|             CONCORD|STATEN ISLAND|515184.0|         61|\n",
      "|       PORT RICHMOND|STATEN ISLAND|516867.0|        155|\n",
      "|       MIDLAND BEACH|STATEN ISLAND|533400.0|        199|\n",
      "|             ARVERNE|       QUEENS|572021.0|        117|\n",
      "+--------------------+-------------+--------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "year = 2021\n",
    "_, name = sales_measures_by_neighborhood(df_sales)\n",
    "view_df = spark.sql(f'''\n",
    "    SELECT neighborhood, borough, ROUND(AvgPrice, 0) as AvgPrice, SalesNumber\n",
    "    FROM {name}\n",
    "    WHERE year = {year}\n",
    "    ORDER BY AvgPrice\n",
    "    LIMIT 10\n",
    "    ''')\n",
    "view_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9cd1ad",
   "metadata": {},
   "source": [
    "## 10 most popular types of locations of incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ab7e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 128:==================================================>  (191 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|       location_type|NumberOfComplaints|\n",
      "+--------------------+------------------+\n",
      "|RESIDENTIAL BUILDING|             96923|\n",
      "|     Street/Sidewalk|             61402|\n",
      "|            Sidewalk|             33508|\n",
      "|Residential Build...|             33300|\n",
      "|              Street|             23756|\n",
      "|    Store/Commercial|              5101|\n",
      "|                Park|              2864|\n",
      "| Club/Bar/Restaurant|              2317|\n",
      "|3+ Family Apt. Bu...|              2011|\n",
      "|               Other|              1585|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_, name = get_incidents_by_type(df_services)\n",
    "view_df = spark.sql(f'''\n",
    "    SELECT location_type, SUM(ComplaintCount) as NumberOfComplaints\n",
    "    FROM {name}\n",
    "    WHERE location_type != 'N/A'\n",
    "    GROUP BY location_type\n",
    "    ORDER BY NumberOfComplaints DESC\n",
    "    LIMIT 10\n",
    "    ''')\n",
    "view_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55fbbc2",
   "metadata": {},
   "source": [
    "## Number of complaints by channel type in selected years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce4c299c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 131:=============================================>       (170 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+--------------+\n",
      "|year|open_data_channel_type|ComplaintCount|\n",
      "+----+----------------------+--------------+\n",
      "|2016|                MOBILE|          9234|\n",
      "|2018|                MOBILE|         13291|\n",
      "|2021|                MOBILE|         19947|\n",
      "|2016|                ONLINE|         20326|\n",
      "|2018|                ONLINE|         29793|\n",
      "|2021|                ONLINE|         42945|\n",
      "|2016|                 OTHER|           927|\n",
      "|2018|                 OTHER|          1425|\n",
      "|2021|                 OTHER|            32|\n",
      "|2016|                 PHONE|         55360|\n",
      "|2018|                 PHONE|         68470|\n",
      "|2021|                 PHONE|         46535|\n",
      "+----+----------------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_, name = get_incidents_by_channel_type(df_services)\n",
    "view_df = spark.sql(f'''\n",
    "    SELECT *\n",
    "    FROM {name}\n",
    "    WHERE  open_data_channel_type != 'UNKNOWN'\n",
    "    ORDER BY open_data_channel_type,  year\n",
    "    ''') \n",
    "view_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f27d16",
   "metadata": {},
   "source": [
    "## 10 streets with most incidents between 4 PM and 8 PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a5f8e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 133:=================================================>   (187 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+--------------+\n",
      "|  borough|       street_name|ComplaintCount|\n",
      "+---------+------------------+--------------+\n",
      "|    BRONX|   GRAND CONCOURSE|           879|\n",
      "|MANHATTAN|          BROADWAY|           827|\n",
      "|MANHATTAN|  AMSTERDAM AVENUE|           529|\n",
      "|    BRONX|  EAST  230 STREET|           475|\n",
      "| BROOKLYN|      OCEAN AVENUE|           416|\n",
      "|    BRONX|  EAST  231 STREET|           405|\n",
      "|    BRONX|     MORRIS AVENUE|           404|\n",
      "|MANHATTAN|ST NICHOLAS AVENUE|           380|\n",
      "|MANHATTAN|          2 AVENUE|           320|\n",
      "|   QUEENS| PARSONS BOULEVARD|           313|\n",
      "+---------+------------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_, name = get_incidents_by_street(df_services, [16, 22])\n",
    "view_df = spark.sql(f'''\n",
    "    SELECT *\n",
    "    FROM {name}\n",
    "    ORDER BY ComplaintCount DESC\n",
    "    LIMIT 10\n",
    "    ''')\n",
    "view_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdbeadb",
   "metadata": {},
   "source": [
    "## Boroughs with most incidents in the morning (7-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30be8356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 137:====================================================>(199 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|      borough|NumberOfComplaints|\n",
      "+-------------+------------------+\n",
      "|     BROOKLYN|             25849|\n",
      "|       QUEENS|             17430|\n",
      "|        BRONX|             15161|\n",
      "|    MANHATTAN|             14712|\n",
      "|STATEN ISLAND|              4240|\n",
      "|  Unspecified|                90|\n",
      "+-------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_, name = get_incidents_by_street(df_services, [7, 11])\n",
    "view_df = spark.sql(f'''\n",
    "    SELECT borough, sum(ComplaintCount) as NumberOfComplaints\n",
    "    FROM {name}\n",
    "    GROUP BY borough\n",
    "    ORDER BY NumberOfComplaints DESC\n",
    "    LIMIT 10\n",
    "    ''')\n",
    "view_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8337d91f",
   "metadata": {},
   "source": [
    "## Boroughs with most incidents in the evening (after 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e0ac442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 141:=================================================>   (188 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|      borough|NumberOfComplaints|\n",
      "+-------------+------------------+\n",
      "|     BROOKLYN|             25053|\n",
      "|        BRONX|             18358|\n",
      "|       QUEENS|             18090|\n",
      "|    MANHATTAN|             17484|\n",
      "|STATEN ISLAND|              3011|\n",
      "|  Unspecified|               133|\n",
      "+-------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_, name = get_incidents_by_street(df_services, [18, 25])\n",
    "view_df = spark.sql(f'''\n",
    "    SELECT borough, sum(ComplaintCount) as NumberOfComplaints\n",
    "    FROM {name}\n",
    "    GROUP BY borough\n",
    "    ORDER BY NumberOfComplaints DESC\n",
    "    LIMIT 10\n",
    "    ''')\n",
    "view_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e23bc",
   "metadata": {},
   "source": [
    "## Boroughs with summary of houses prices, number of complaints and most common type of complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c38813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 196:===============================================>     (179 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+--------+---------+---------+--------------+--------------------+\n",
      "|      borough|SalesNumber|MinPrice| AvgPrice| MaxPrice|ComplaintCount|MostPopularComplaint|\n",
      "+-------------+-----------+--------+---------+---------+--------------+--------------------+\n",
      "|        BRONX|       8490|  200000| 628191.0|8000000.0|         70158|      HEAT/HOT WATER|\n",
      "|STATEN ISLAND|      15360|  200000| 645265.0|    1.7E7|         16073|Request Large Bul...|\n",
      "|       QUEENS|      29876|  200000| 835233.0|7750000.0|         79066|     Illegal Parking|\n",
      "|     BROOKLYN|      20413|  200000|1621919.0|   2.25E7|        105544|      HEAT/HOT WATER|\n",
      "|    MANHATTAN|        699|  250000|5913766.0|    5.9E7|         68792|      HEAT/HOT WATER|\n",
      "+-------------+-----------+--------+---------+---------+--------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1, name1 = sales_measures(df_sales)\n",
    "df2, name2 = get_incidents_by_borough(df_services)\n",
    "df3, name3 = get_popular_incidents(df_services)\n",
    "result = spark.sql(f'''\n",
    "    SELECT s.borough, SalesNumber, MinPrice, ROUND(AvgPrice, 0) as AvgPrice, MaxPrice, i.ComplaintCount, p.complaint_type AS MostPopularComplaint\n",
    "    FROM {name1} s INNER JOIN {name2} i ON s.borough = i.borough\n",
    "    INNER JOIN {name3} p ON s.borough = p.borough\n",
    "    ORDER BY AvgPrice\n",
    "    ''')\n",
    "result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
